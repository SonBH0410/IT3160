{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIGvP10nEdOr"
      },
      "source": [
        "# **# Import packets and libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAkN6p17wco8",
        "outputId": "7f2c4cc5-c1e0-42eb-b79f-5ff060451331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bBfyhkhyCyfm",
        "outputId": "1f09f22a-da49-460c-e0ce-47be55fcb189"
      },
      "outputs": [],
      "source": [
        "# Thiết lập seed ngẫu nhiên cho Python, NumPy và PyTorch\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIg07lui3LtF"
      },
      "outputs": [],
      "source": [
        "# Import Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# import wandb\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from piq import ssim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qt8Dm-qE0a5"
      },
      "source": [
        "# **# Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDC7Dhn8n-0g"
      },
      "outputs": [],
      "source": [
        "# **# Thay đường dẫn [FILE].json vào đây**\n",
        "with open('/content/drive/MyDrive/UTBT_DATASET/OTU_2D/OTU_2D_annotation.json', 'r') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTETD6p1o5uh"
      },
      "outputs": [],
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "test_x  = []\n",
        "test_y  = []\n",
        "valid_x = []\n",
        "valid_y = []\n",
        "\n",
        "path = \"/content/drive/MyDrive/UTBT_DATASET/\"\n",
        "for i in data :\n",
        "    if i['split'] == 'train' :\n",
        "        img_path = path + str(i['file_path_img'])\n",
        "        ann_path = path + str(i['file_path_ann'])\n",
        "        train_x.append(img_path)\n",
        "        train_y.append(ann_path)\n",
        "    if i['split'] == 'test' :\n",
        "        img_path = path + str(i['file_path_img'])\n",
        "        ann_path = path + str(i['file_path_ann'])\n",
        "        test_x.append(img_path)\n",
        "        test_y.append(ann_path)\n",
        "    if i['split'] == 'validation' :\n",
        "        img_path = path + str(i['file_path_img'])\n",
        "        ann_path = path + str(i['file_path_ann'])\n",
        "        valid_x.append(img_path)\n",
        "        valid_y.append(ann_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUOxxOK5XYTZ"
      },
      "outputs": [],
      "source": [
        "images_arr = train_x + valid_x + test_x\n",
        "annotations_arr = train_y + valid_y + test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8jg82ITi8I-"
      },
      "source": [
        "# **# Import function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFPmUXLppC6V"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 256  # Image size\n",
        "EPOCHS = 30       # Epochs\n",
        "BATCH = 8         # Batch size\n",
        "LR = 1e-4         # Learning rate 10^-4 = 0.0001\n",
        "\n",
        "class Augment(torch.nn.Module):\n",
        "    def __init__(self, seed=42):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(seed)\n",
        "        self.augment = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(20),\n",
        "        ])\n",
        "\n",
        "    def forward(self, inputs, labels):\n",
        "        seed = torch.random.initial_seed()\n",
        "        torch.manual_seed(seed)\n",
        "        inputs = self.augment(inputs)\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "        labels = self.augment(labels)\n",
        "        return inputs, labels\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "        # image[image > 0] = 255\n",
        "        # mask[mask > 0] = 255\n",
        "        image = image / 255.0\n",
        "        mask = mask / 255.0\n",
        "\n",
        "        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension to mask\n",
        "\n",
        "        image = TF.to_tensor(image).float()\n",
        "        mask = TF.to_tensor(mask).float()\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "def get_dataloader(image_paths, mask_paths, batch_size=8, shuffle=True):\n",
        "    dataset = CustomDataset(image_paths, mask_paths)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataloader\n",
        "\n",
        "train_dataloader = get_dataloader(train_x, train_y, batch_size = BATCH, shuffle = False)\n",
        "valid_dataloader = get_dataloader(valid_x, valid_y, batch_size = BATCH, shuffle = False)\n",
        "test_dataloader = get_dataloader(test_x, test_y, batch_size = BATCH, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCknID8BnJtS",
        "outputId": "2cff401f-e3bc-4150-834f-bfef5982ab7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7837ffbb0850>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7837ffbb3f70>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7837ffbb3670>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataloader)\n",
        "print(valid_dataloader)\n",
        "print(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO0axEBqK_bD"
      },
      "source": [
        "# **# Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbOhE1hI34C7"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9koB0AUKD4s",
        "outputId": "0f49b6fd-a634-4909-ccdb-0e39b6b3aa09"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        return x\n",
        "\n",
        "# class EncoderBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(EncoderBlock, self).__init__()\n",
        "#         self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         conv = self.conv_block(x)\n",
        "#         pooled = self.pool(conv)\n",
        "#         return conv, pooled\n",
        "\n",
        "class AttentionGate(nn.Module):\n",
        "    def __init__(self, g_channels, s_channels, inter_channels):\n",
        "        super(AttentionGate, self).__init__()\n",
        "        self.Wg = nn.Sequential(\n",
        "            nn.Conv2d(g_channels, inter_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(inter_channels)\n",
        "        )\n",
        "        self.Ws = nn.Sequential(\n",
        "            nn.Conv2d(s_channels, inter_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(inter_channels)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(inter_channels, 1, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, g, s):\n",
        "        g_conv = self.Wg(g)\n",
        "        s_conv = self.Ws(s)\n",
        "        psi = self.psi(F.relu(g_conv + s_conv))\n",
        "        return s * psi\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, s_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.att_gate = AttentionGate(in_channels, s_channels, out_channels)\n",
        "        self.conv_block = ConvBlock(in_channels + s_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, s):\n",
        "        x = self.up(x)\n",
        "        s = self.att_gate(x, s)\n",
        "        x = torch.cat([x, s], dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "class SPPFModule(nn.Module):\n",
        "    def __init__(self, in_channels, k=5):\n",
        "        super(SPPFModule, self).__init__()\n",
        "        self.cv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 2, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels // 2),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "        self.mp1 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
        "        self.mp2 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
        "        self.mp3 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels // 2 * 4, in_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        cv1 = self.cv1(x)\n",
        "        mp1 = self.mp1(cv1)\n",
        "        mp2 = self.mp2(cv1)\n",
        "        mp3 = self.mp3(cv1)\n",
        "        out = torch.cat([mp1, mp2, mp3], dim=1)\n",
        "        out = self.final_conv(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class VGG16AttentionUNet(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(VGG16AttentionUNet, self).__init__()\n",
        "        vgg16_model = vgg16(pretrained=True)\n",
        "        vgg16_features = vgg16_model.features\n",
        "\n",
        "        self.feature1 = nn.Sequential(*vgg16_features[:5])\n",
        "        self.feature2 = nn.Sequential(*vgg16_features[5:10])\n",
        "        self.feature3 = nn.Sequential(*vgg16_features[10:17])\n",
        "        self.feature4 = nn.Sequential(*vgg16_features[17:24])\n",
        "        self.encoder = nn.Sequential(*vgg16_features[24:30])\n",
        "\n",
        "        self.sppf_module = SPPFModule(in_channels=512)\n",
        "\n",
        "        self.decoder1 = DecoderBlock(512, 512, 512)\n",
        "        self.decoder2 = DecoderBlock(512, 256, 256)\n",
        "        self.decoder3 = DecoderBlock(256, 128, 128)\n",
        "        self.decoder4 = DecoderBlock(128, 64, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1 = self.feature1(x)       ; print(s1.shape)\n",
        "        s2 = self.feature2(s1)      ; print(s2.shape)\n",
        "        s3 = self.feature3(s2)      ; print(s3.shape)\n",
        "        s4 = self.feature4(s3)      ; print(s4.shape)\n",
        "        b1 = self.encoder(s4)       ; print(b1.shape)\n",
        "        b2 = self.sppf_module(b1)   ; print(b2.shape)\n",
        "\n",
        "        d4 = self.decoder1(b2, s4)  ; print(d4.shape)\n",
        "        d3 = self.decoder2(d4, s3)  ; print(d3.shape)\n",
        "        d2 = self.decoder3(d3, s2)  ; print(d2.shape)\n",
        "        d1 = self.decoder4(d2, s1)  ; print(d1.shape)\n",
        "\n",
        "        out = self.final_conv(d1)   ; print(out.shape)\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "# Kiểm tra với một đầu vào ngẫu nhiên\n",
        "model = VGG16AttentionUNet(num_classes=1)\n",
        "x = torch.randn(1, 3, 256, 256)\n",
        "output = model(x)\n",
        "print(output.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESRRfam-wrOQ"
      },
      "source": [
        "# **# Import Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNPl3gzSZke2"
      },
      "outputs": [],
      "source": [
        "# Định nghĩa các hàm loss và metrics\n",
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "\n",
        "def focal_loss_with_logits(logits, labels, alpha, gamma, y_pred):\n",
        "    weight_a = alpha * torch.pow(1 - y_pred, gamma) * labels\n",
        "    weight_b = (1 - alpha) * torch.pow(y_pred, gamma) * (1 - labels)\n",
        "    logit_loss = (torch.log1p(torch.exp(-torch.abs(logits))) + F.relu(-logits))\n",
        "    loss = logit_loss * (weight_a + weight_b) + logits * weight_b\n",
        "    return loss\n",
        "\n",
        "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2):\n",
        "    y_pred = torch.clamp(y_pred, min=1e-7, max=1 - 1e-7)\n",
        "    logits = torch.log(y_pred / (1 - y_pred))\n",
        "    loss = focal_loss_with_logits(logits=logits, labels=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
        "    return loss.mean()\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1e-5, threshold=0.5):\n",
        "    y_true_pos = apply_threshold(y_true, threshold)\n",
        "    y_pred_pos = apply_threshold(y_pred, threshold)\n",
        "    y_true_f = torch.flatten(y_true_pos)\n",
        "    y_pred_f = torch.flatten(y_pred_pos)\n",
        "    intersection = torch.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred, threshold=0.5):\n",
        "    return 1 - dice_coef(y_true, y_pred, threshold=threshold)\n",
        "\n",
        "def jacard_similarity(y_true, y_pred, threshold=0.5):\n",
        "    y_true_pos = apply_threshold(y_true, threshold)\n",
        "    y_pred_pos = apply_threshold(y_pred, threshold)\n",
        "    y_true_f = torch.flatten(y_true_pos)\n",
        "    y_pred_f = torch.flatten(y_pred_pos)\n",
        "    intersection = torch.sum(y_true_f * y_pred_f)\n",
        "    union = torch.sum((y_true_f + y_pred_f) - (y_true_f * y_pred_f))\n",
        "    return intersection / union\n",
        "\n",
        "def jacard_loss(y_true, y_pred, threshold=0.5):\n",
        "    return 1 - jacard_similarity(y_true, y_pred, threshold=threshold)\n",
        "\n",
        "def ssim_loss(y_true, y_pred):\n",
        "    ssim_value = ssim(y_pred, y_true, data_range=1.0)\n",
        "    return 1 - ssim_value.mean()\n",
        "\n",
        "def joint_loss1(y_true, y_pred, threshold=0.5):\n",
        "    focal_loss1 = focal_loss(y_true, y_pred)\n",
        "    ms_ssim_loss1 = ssim_loss(y_true, y_pred)\n",
        "    jacard_loss1 = jacard_loss(y_true, y_pred, threshold=threshold)\n",
        "    loss = (focal_loss1 + ms_ssim_loss1 + jacard_loss1) / 3\n",
        "    return loss\n",
        "\n",
        "def evaluate_metrics(y_true, y_pred, threshold=0.5):\n",
        "    dc = dice_coef(y_true, y_pred, threshold=threshold)\n",
        "    js = jacard_similarity(y_true, y_pred, threshold=threshold)\n",
        "    pre = precision(y_true, y_pred, threshold=threshold)\n",
        "    rec = recall(y_true, y_pred, threshold=threshold)\n",
        "    return dc, js, pre, rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10farYprbRys",
        "outputId": "be315f54-4701-4d51-8e99-55a7647d718d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dice Coefficient: 1.0\n",
            "IoU: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Giả sử y_true và y_pred là các tensor dự đoán và ground truth của bạn\n",
        "    y_true = torch.rand((1, 1, 256, 256))\n",
        "    # y_true[y_true > 0] = 255\n",
        "    # y_true = y_true / 255\n",
        "\n",
        "    y_pred = torch.rand((1, 1, 256, 256))\n",
        "\n",
        "    # Đánh giá các metrics với ngưỡng 0.5\n",
        "    dc, js, pre, rec = evaluate_metrics(y_true, y_true, threshold=0.5)\n",
        "\n",
        "    print(f'Dice Coefficient: {dc.item()}')\n",
        "    print(f'IoU: {js.item()}')\n",
        "    print(f'Precision: {pre.item()}')\n",
        "    print(f'Recall: {rec.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghiVkvin3HVz"
      },
      "source": [
        "# **# Compile Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtS4rqmdMFOu",
        "outputId": "77a28281-02f1-4a89-a82a-ba6b6ae8e92f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG16AttentionUNet().to(device)\n",
        "\n",
        "loss_function = joint_loss1\n",
        "num_classes = 1\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "metrics = [\n",
        "    dice_coef,\n",
        "    jacard_similarity,\n",
        "    precision,\n",
        "    recall\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "QTUfFWpxkp4U",
        "outputId": "a92f0d06-4689-40bf-f541-fb567e80d17b"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch = epoch + 30\n",
        "    print(f\"EPOCH: {epoch + 1}/{EPOCHS}\")\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_metrics = {metric.__name__: 0 for metric in metrics}\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss_total = loss_function(labels, outputs)\n",
        "\n",
        "        loss_total.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss_total.item()\n",
        "\n",
        "        for metric in metrics:\n",
        "            metric_value = metric(labels, outputs)\n",
        "            train_metrics[metric.__name__] += metric_value\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    for metric_name in train_metrics:\n",
        "        train_metrics[metric_name] = len(train_dataloader)\n",
        "\n",
        "    print(\"Train_loss: {:.4f} - Train_Dice: {:.4f} - Train_Jaccard : {:.4f} - Train_Precision: {:.4f} - Train_Recall: {:.4f}\".format(train_loss, train_metrics['dice_coef'], train_metrics['jacard_similarity'], train_metrics['precision'], train_metrics['recall']))\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_metrics = {metric.__name__: 0 for metric in metrics}\n",
        "\n",
        "    with torch.no_grad():  # Không tính gradient\n",
        "        for inputs, labels in valid_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss_total = loss_function(labels, outputs)\n",
        "\n",
        "            val_loss += loss_total.item()\n",
        "\n",
        "            for metric in metrics:\n",
        "                metric_value = metric(labels, outputs)\n",
        "                val_metrics[metric.__name__] += metric_value\n",
        "\n",
        "        # Trung bình hóa loss và metrics\n",
        "        val_loss /= len(valid_dataloader)\n",
        "        for metric_name in val_metrics:\n",
        "            val_metrics[metric_name] / len(valid_dataloader)\n",
        "\n",
        "        print(\"val_loss: {:.4f} - val_Dice: {:.4f} - val_Jaccard : {:.4f} - val_Precision: {:.4f} - val_Recall: {:.4f}\".format(val_loss, val_metrics['dice_coef'], val_metrics['jacard_similarity'], val_metrics['precision'], val_metrics['recall']))\n",
        "\n",
        "    # checkpoint_path = os.path.join(checkpoint_dir, f'Epoch_{epoch+1}.pth')\n",
        "    # torch.save(model.state_dict(), checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsZMEVzRnAhs",
        "outputId": "bbb8e483-a48a-47e2-9134-97ffe8d2327c"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "test_loss = 0\n",
        "test_metrics = {metric.__name__: 0 for metric in metrics}\n",
        "\n",
        "with torch.no_grad():  # Không tính gradient\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss_total = loss_function(labels, outputs)\n",
        "\n",
        "        test_loss += loss_total.item()\n",
        "\n",
        "        for metric in metrics:\n",
        "            metric_value = metric(labels, outputs)\n",
        "            test_metrics[metric.__name__] += metric_value\n",
        "\n",
        "        # Trung bình hóa loss và metrics\n",
        "    test_loss /= len(test_dataloader)\n",
        "    for metric_name in test_metrics:\n",
        "        test_metrics[metric_name] /= len(test_dataloader)\n",
        "\n",
        "    print(\"test_loss: :.4f} - test_Dice: {:.4f} - test_Jaccard : {:.4f} - test_Precision: {:.4f} - test_Recall: {:.4f}\".format(test_loss, test_metrics['dice_coef'], test_metrics['jacard_similarity'], test_metrics['precision'], test_metrics['recall']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
